# WikiBench

**Русский бенчмарк для оценки аналитических способностей больших языковых моделей посредством генерации статей в стиле Википедии**

---

## Содержание

1. [Описание](#описание)
2. [Кратко об этапах оценки](#кратко-об-этапах-оценки)
3. [Структура репозитория](#структура-репозитория)
4. [Установка](#установка)
5. [Подготовка окружения](#подготовка-окружения)
6. [Пример использования](#пример-использования)

---

## Описание

WikiBench — это бенчмарк, предоставляющий метод оценки, состоящий из трех этапов, который проверяет, насколько хорошо языковая модель умеет:

1. **Находить и ранжировать релевантные источники** для статьи "Рувики";
2. **Формировать связный план статьи** на базе предоставленных источников;
3. **Писать качественный текст секций**, опираясь исключительно на информацию из соответствующих источников.

Бенчмарк полностью автоматизирован и включает:

* Подборку статей российской интернет-энциклопедии "Рувики";
* Эталонные тексты источников и ссылки на них;
* Метрики для каждого этапа;
* Удобный Python‑интерфейс (`WikiBench`).

---

## Кратко об этапах оценки

### Этап 1: Ранжирование

BM25 выдает смесь релевантных и нерелевантынх сниппетов; модель помечает каждый как "да/нет". Оценка строится по лог‑вероятностям ответов, стимулируя как правильность, так и уверенность в ответе.

### Этап 2: План

Сниппеты преобразуются в эмбеддинги и кластеризуются. Модель получает либо тексты кластеров, либо их краткие описания и формирует иерархический план статьи.

### Этап 3: Секции

Для каждой секции берутся свои сниппеты, группируются по косинусному сходству (>0.8), после чего модель итеративно разворачивает краткие описания групп в полноценный текст секции.

---

## Структура репозитория

```text
.
├── Articles/                     # Данные для оценки
│   ├── Sources/                  # Тексты источников, сгруппированные по статьям
│   └── Downloaded_Sources_List/  # Сохраненные скачанные ссылки источников (в виде id из исходной статьи)
│   └── Html/                     # Сохраненные HTML-коды статей
├── Utils/                        # Закешированные обработанные данные
│   ├── bm25_index/               # Проиндексированный в BM25 корпус
│   ├── embeddings/               # Эмбеддинги текстов сниппетов
│   ├── text_corpus/              # Набор сниппетов
├── src/                          # Исходный код бенчмарка
│   ├── openai_utils.py           # LLMCompleter для обращения к LLM + AsyncList
│   ├── wiki_parse.py             # WikiParse — парсер HTML Википедии
│   ├── wiki_extract.py           # WikiExtracter — скачивание источников
│   ├── wiki_gen.py               # WikiGen — все промпты для генерации и обработка запросов
│   ├── wiki_utils.py             # WikiUtils — сниппеты, эмбеддинги, BM25 и др.
│   ├── wiki_agent.py             # WikiAgent — агент для прогона задач бенчмарка
│   ├── wiki_evaluater.py         # WikiEval — оценка выдачи ответа модели
│   └── wiki_bench.py             # WikiBench — основной модуль, объединяющий все вышеперечисленные
├── main.ipynb                    # Демонстрация работы бенчмарка
├── ruwikibench_articles.json     # Данные бенчмарка в json файле
├── manage_dataset_structure.py   # Скрипт для преобразования json в обычную файловую систему
└── requirements.txt              # Необходимые модули и библиотеки
```

---

## Установка

```bash
# 1. Клонируем репозиторий
$ git clone https://github.com/Nejimaki-Tori/WikiBench.git
$ cd WikiBench

# 2. Устанавливаем зависимости
$ pip install -r requirements.txt
```

---

## Подготовка окружения

Для того, чтобы воспользоваться бенчмарком, необходимо подготовить окружение. Для этого достаточно скачать файл ruwikibench_articles.json (https://huggingface.co/datasets/NejimakiTori/RuWikiBench) и запустить в той же директории скрипт manage_dataset_structure.py.
Тогда json файл будет распакован в рабочие директории для бенчмарка.

Далее необходимо запустить скрипт WikiBench.prepare_env().
- are_texts_ready - используется для скачивания html кода статей напрямую с Рувики. По умолчанию установлен на True, не нужно менять, если нет острой необходимости скачать все статьи заново.
- window_size - размер сниппетов (по умолчанию - 600)
- overlap - перекрытие сниппетов (по умолчанию - 0)

В результате будет создан проиндексированный в bm25 корпус, а также словарь сниппетов и заранее посчитанные эмбеддинги.

## Пример использования

```python
import sys
import logging
import torch
sys.path.append('src')
from wiki_bench import WikiBench
from sentence_transformers import SentenceTransformer

# можно создать файл Access_key.txt и указать там url и key
# with open('Access_key.txt', 'r', encoding='utf-8') as file:
#    url, key = file.read().split()

logging.getLogger('sentence_transformers.SentenceTransformer').setLevel(logging.ERROR)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
encoder = SentenceTransformer('sergeyzh/BERTA').to(device)

bench = WikiBench(
    key='KEY', # key=key
    url='URL', # url=url
    model_name='ruadapt-qwen3-4b', # example model name
    device=device, # 'cuda'
    encoder=encoder, # 'sergeyzh/BERTA' - default
    number_of_articles=3 # число статей для подсчета
)

# подготовка окружения (корпус уже должен быть готов!)
bench.load_enviroment()

# Ранжирование источников
score_query = await bench.rank_query()
print("Score (query):", score_query)

# Генерация плана
score_outline = await bench.rank_outline(
    neighbor_count=0,
    description_mode=0,
    clusterization_with_hint=True             
)
print("Score (outline):", score_outline)

# Генерация секций
score_sections = await bench.rank_sections()
print("Score (sections):", score_sections)
```

Каждый метод возвращает кортеж с числовыми значениями метрик. Можно вызывать их отдельно или все сразу.
---
