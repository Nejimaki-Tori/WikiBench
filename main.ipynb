{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8632f9-b953-47c5-8045-542c52621be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia==1.4.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: requests==2.28.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 2)) (2.28.0)\n",
      "Requirement already satisfied: BeautifulSoup4==4.11.1 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 3)) (4.11.1)\n",
      "Requirement already satisfied: Wikipedia-Api==0.5 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 4)) (0.5.0)\n",
      "Requirement already satisfied: trafilatura==0.9.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: lxml_html_clean==0.4.1 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: openai==1.55.3 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 8)) (1.55.3)\n",
      "Requirement already satisfied: httpx==0.27.2 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 9)) (0.27.2)\n",
      "Requirement already satisfied: asyncio==3.4.3 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 10)) (3.4.3)\n",
      "Requirement already satisfied: scipy==1.15.2 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from -r requirements.txt (line 11)) (1.15.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from requests==2.28.0->-r requirements.txt (line 2)) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from requests==2.28.0->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from requests==2.28.0->-r requirements.txt (line 2)) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from requests==2.28.0->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from BeautifulSoup4==4.11.1->-r requirements.txt (line 3)) (2.5)\n",
      "Requirement already satisfied: courlan>=0.4.1 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from trafilatura==0.9.0->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: htmldate>=0.9.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from trafilatura==0.9.0->-r requirements.txt (line 5)) (1.2.3)\n",
      "Requirement already satisfied: justext>=2.2.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from trafilatura==0.9.0->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: lxml>=4.6.3 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from trafilatura==0.9.0->-r requirements.txt (line 5)) (5.3.1)\n",
      "Requirement already satisfied: readability-lxml>=0.8.1 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from trafilatura==0.9.0->-r requirements.txt (line 5)) (0.8.1)\n",
      "Requirement already satisfied: chardet>=4.0.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from trafilatura==0.9.0->-r requirements.txt (line 5)) (5.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from tqdm==4.67.1->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from openai==1.55.3->-r requirements.txt (line 8)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from openai==1.55.3->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from openai==1.55.3->-r requirements.txt (line 8)) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from openai==1.55.3->-r requirements.txt (line 8)) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from openai==1.55.3->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from openai==1.55.3->-r requirements.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from httpx==0.27.2->-r requirements.txt (line 9)) (1.0.7)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from scipy==1.15.2->-r requirements.txt (line 11)) (2.2.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from httpcore==1.*->httpx==0.27.2->-r requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: babel>=2.16.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from courlan>=0.4.1->trafilatura==0.9.0->-r requirements.txt (line 5)) (2.17.0)\n",
      "Requirement already satisfied: tld>=0.13 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from courlan>=0.4.1->trafilatura==0.9.0->-r requirements.txt (line 5)) (0.13)\n",
      "Requirement already satisfied: dateparser>=1.1.1 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from htmldate>=0.9.0->trafilatura==0.9.0->-r requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from htmldate>=0.9.0->trafilatura==0.9.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.3->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.55.3->-r requirements.txt (line 8)) (2.27.2)\n",
      "Requirement already satisfied: cssselect in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from readability-lxml>=0.8.1->trafilatura==0.9.0->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2024.2 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from dateparser>=1.1.1->htmldate>=0.9.0->trafilatura==0.9.0->-r requirements.txt (line 5)) (2025.1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from dateparser>=1.1.1->htmldate>=0.9.0->trafilatura==0.9.0->-r requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: tzlocal>=0.2 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from dateparser>=1.1.1->htmldate>=0.9.0->trafilatura==0.9.0->-r requirements.txt (line 5)) (5.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from python-dateutil>=2.8.2->htmldate>=0.9.0->trafilatura==0.9.0->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\dagri\\anaconda3\\envs\\wikibench\\lib\\site-packages (from tzlocal>=0.2->dateparser>=1.1.1->htmldate>=0.9.0->trafilatura==0.9.0->-r requirements.txt (line 5)) (2025.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10fe472-7e94-41f7-843b-5a33f1eb770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a4b5ec-3805-4a98-9942-d5b12d1bb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6664a03f-3846-48ae-8bcc-6377651f84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216bea97-a5c3-464b-8015-5d87020be620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiki_extract import Extracter\n",
    "from wiki_gen import WikiGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b4a312-18dc-4047-acd8-da3ea801094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(name):\n",
    "    print('Article name: ', name)\n",
    "    page = Extracter(name)\n",
    "    page.get_references()\n",
    "    page.get_outline()\n",
    "    page.get_reference_positions()\n",
    "    page.newspaper_ref()\n",
    "    page.get_filtered_outline()\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e21955e3-1b7f-4abc-ac9f-e5ca0ccabaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_names = [\n",
    "    'Python',\n",
    "    'Летние Олимпийские игры 2024',\n",
    "    'Квантовый компьютер',\n",
    "    'Присоединение Крыма к Российской Федерации',\n",
    "    'Сколково (инновационный центр)',\n",
    "    'Tomb Raider (игра, 2013)',\n",
    "    'Чёрная дыра',\n",
    "    'Экономика США',\n",
    "    'Искусственный интеллект',\n",
    "    'COVID-19',\n",
    "    'Броненосный крейсер',\n",
    "    'Применение искусственного интеллекта',\n",
    "    'РИА Новости'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92438061-70a2-4ca0-8ca3-460d25428830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_texts(article_name, texts, number):\n",
    "\n",
    "    directory = os.path.join(\"Articles\", \"Sources\", article_name)\n",
    "\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    '''\n",
    "    for i, text in enumerate(texts, start=number):\n",
    "        file_path = os.path.join(directory, f\"source_{i}.txt\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a0577b-98af-4a5c-92f9-35f697e0bd7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article name:  COVID-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating outline: 100%|██████████| 191/191 [00:00<00:00, 38450.30it/s]\n",
      "Getting link numbers: 100%|██████████| 257/257 [00:02<00:00, 118.88it/s]\n",
      "Calculating reference positions: 100%|██████████| 57/57 [00:00<00:00, 57332.21it/s]\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Retrieving sources: 100%|██████████| 257/257 [51:18<00:00, 11.98s/it]\n",
      "Getting link numbers: 100%|██████████| 257/257 [00:03<00:00, 69.54it/s]\n",
      "Calculating reference positions: 100%|██████████| 57/57 [00:00<00:00, 56963.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article name:  Броненосный крейсер\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating outline: 100%|██████████| 282/282 [00:00<00:00, 40277.66it/s]\n",
      "Getting link numbers: 100%|██████████| 180/180 [00:01<00:00, 110.23it/s]\n",
      "Calculating reference positions: 100%|██████████| 31/31 [00:00<00:00, 23949.79it/s]\n",
      "Retrieving sources: 100%|██████████| 180/180 [01:49<00:00,  1.64it/s]\n",
      "Getting link numbers: 100%|██████████| 180/180 [00:01<00:00, 120.29it/s]\n",
      "Calculating reference positions: 100%|██████████| 31/31 [00:00<00:00, 30994.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article name:  Применение искусственного интеллекта\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating outline: 100%|██████████| 151/151 [00:00<00:00, 42926.66it/s]\n",
      "Getting link numbers: 100%|██████████| 224/224 [00:01<00:00, 133.01it/s]\n",
      "Calculating reference positions: 100%|██████████| 48/48 [00:00<00:00, 90362.03it/s]\n",
      "Retrieving sources: 100%|██████████| 224/224 [15:20<00:00,  4.11s/it] \n",
      "Getting link numbers: 100%|██████████| 224/224 [00:01<00:00, 211.95it/s]\n",
      "Calculating reference positions: 100%|██████████| 48/48 [00:00<00:00, 48049.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article name:  РИА Новости\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating outline: 100%|██████████| 102/102 [00:00<00:00, 50031.46it/s]\n",
      "Getting link numbers: 100%|██████████| 83/83 [00:00<00:00, 596.51it/s]\n",
      "Calculating reference positions: 100%|██████████| 31/31 [00:00<00:00, 31002.25it/s]\n",
      "Retrieving sources: 100%|██████████| 83/83 [20:11<00:00, 14.60s/it]\n",
      "Getting link numbers: 100%|██████████| 83/83 [00:00<00:00, 598.82it/s]\n",
      "Calculating reference positions: 100%|██████████| 31/31 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "articles = {}\n",
    "\n",
    "for name in article_names:\n",
    "    page = get_article(name)\n",
    "    articles[name] = page.ref_texts.keys()\n",
    "    num = 1\n",
    "    for _, texts in page.ref_texts.items():\n",
    "        save_texts(page.name, texts, num)\n",
    "        num += len(texts)\n",
    "\n",
    "with open('saved_ref.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(articles, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c830643c-8a34-410c-bd43-5997626e4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "oclient = OpenAI(api_key=KEY, base_url=URL)\n",
    "\n",
    "wiki_writer = WikiGen(oclient)\n",
    "\n",
    "for name in article_names:\n",
    "\n",
    "    json_str = wiki_writer.get_subqueries(name)\n",
    "\n",
    "    if json_str:\n",
    "        data = json.loads(json_str)\n",
    "        directory = os.path.join(\"Generation\", \"Subqueries\", name)\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        filename = name.replace(\" \", \"_\") + '.json'\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85fcd875-e500-442d-b298-a1d04536415e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.8214285714285714\n",
      "0.9090909090909091\n",
      "0.9325153374233128\n",
      "0.8518518518518519\n",
      "0.972972972972973\n",
      "1.0\n",
      "0.967741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dagri\\anaconda3\\envs\\WIKIbench\\Lib\\typing.py:430: RuntimeWarning: coroutine 'WikiGen.process_text' was never awaited\n",
      "  ev_args = tuple(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.8873239436619719\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from openai_utils import LlmCompleter\n",
    "\n",
    "client = LlmCompleter(api_address=URL, api_key=KEY)\n",
    "wiki_writer = WikiGen(client)\n",
    "\n",
    "\n",
    "for name in article_names:\n",
    "    topic = name\n",
    "    texts = []\n",
    "    file_names = []\n",
    "    directory = 'Articles/Sources/' + name\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.txt'):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                texts.append(f.read())\n",
    "            file_names.append(file)\n",
    "    \n",
    "    lst = await wiki_writer.filter_sources(topic, \"\", texts)\n",
    "    #print(lst)\n",
    "    c = 0\n",
    "    for elem in lst:\n",
    "        if elem[1] > 0.5:\n",
    "            c += 1\n",
    "    print(c / len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "394b9d34-95b2-4bdd-bc32-9f6e1edf5d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"article_title\": \"COVID-19\",\n",
      "  \"subqueries\": [\n",
      "    \"Каковы основные пути передачи вируса SARS-CoV-2 и какие меры предотвращения наиболее эффективны?\",\n",
      "    \"Какие симптомы и клинические проявления характерны для COVID-19, и как они различаются у разных групп населения?\",\n",
      "    \"Какие методы диагностики COVID-19 существуют, и какие из них наиболее точны и доступны?\",\n",
      "    \"Какие вакцины против COVID-19 были разработаны, и каковы их эффективность и побочные эффекты?\",\n",
      "    \"Какие экономические последствия вызвал пандемический кризис, и какие меры поддержки были приняты правительствами?\",\n",
      "    \"Как пандемия COVID-19 повлияла на образование, работу и социальные взаимодействия?\",\n",
      "    \"Какие научные исследования проводятся для изучения долгосрочных последствий COVID-19 для здоровья?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(await wiki_writer.get_subqueries('COVID-19'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e04a6-ced3-4c86-a89a-c867702c4438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
